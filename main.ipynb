{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0feb0747",
   "metadata": {},
   "source": [
    "# HuMAR Model Testing - Backbone Issues FIXED ✅\n",
    "\n",
    "## What Was Wrong?\n",
    "All timm-based backbones (MobileViT, EfficientFormer, PoolFormer) and SegFormer were crashing with:\n",
    "```\n",
    "TypeError: conv2d() received an invalid combination of arguments - got (NestedTensor, Parameter, ...)\n",
    "```\n",
    "\n",
    "## What Got Fixed?\n",
    "✅ **MobileViT** - Now extracts tensor from NestedTensor before processing  \n",
    "✅ **SegFormer** - Now handles NestedTensor properly  \n",
    "✅ **EfficientFormer** - Now extracts tensor from NestedTensor  \n",
    "✅ **PoolFormer** - Now extracts tensor from NestedTensor  \n",
    "\n",
    "All backbones now return `Dict[str, NestedTensor]` matching the expected format.\n",
    "\n",
    "## IMPORTANT: You MUST Restart the Kernel!\n",
    "1. Click **Kernel → Restart Kernel** (or press restart button)\n",
    "2. Re-run cells from the top\n",
    "3. Test different backbones!\n",
    "\n",
    "## Available Backbones (All Working Now!)\n",
    "\n",
    "**Lightweight (Best for RTX 4050 6GB):**\n",
    "- `mobilevit_xxs` - 1.3M params, ultra-fast ⚡⚡⚡⚡⚡\n",
    "- `segformer_mit_b0` - 3.7M params, best efficiency ⭐\n",
    "\n",
    "**Balanced:**\n",
    "- `mobilevit_xs` - 2.3M params\n",
    "- `mobilevit_s` - 5.6M params\n",
    "- `segformer_mit_b1` - 13.7M params\n",
    "\n",
    "**Higher Capacity:**\n",
    "- `poolformer_s12` - 12M params\n",
    "- `swin_T_224_1k` - 28M params (original)\n",
    "\n",
    "See [BACKBONE_FIX_SUMMARY.md](BACKBONE_FIX_SUMMARY.md) for detailed troubleshooting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eb17d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniPHDArgs:\n",
    "    def __init__(self):\n",
    "        # -----------------------------\n",
    "        # Config / Override Parameters\n",
    "        # -----------------------------\n",
    "        self.config_file = \"\"           # REQUIRED: path to .py config\n",
    "        self.options = None             # List of overrides via DictAction (e.g., [\"lr=1e-4\"])\n",
    "\n",
    "        # -----------------------------\n",
    "        # Prompt / Text Encoder\n",
    "        # -----------------------------\n",
    "        self.freeze_text_encoder = False\n",
    "        self.train_trigger = \"text scribble point\"\n",
    "        self.eval_trigger = \"text\"\n",
    "\n",
    "        self.kps_visi_trigger = True\n",
    "        self.pose_guide_trigger = False\n",
    "        self.late_within_attn_trigger = True\n",
    "        self.within_type = \"attn_graph\"\n",
    "        self.no_mask = False\n",
    "\n",
    "        # -----------------------------\n",
    "        # Model Backbone\n",
    "        # -----------------------------\n",
    "        self.backbone = \"mobilevit_xxs\"\n",
    "        self.swin_pretrain_path = r\"C:\\Users\\nikhi\\Desktop\\HuMAR\\datasets\\RefHuman\"\n",
    "\n",
    "        # -----------------------------\n",
    "        # Dataset Parameters\n",
    "        # -----------------------------\n",
    "        self.dataset_file = \"refhuman\"\n",
    "        self.coco_path = \"../datasets/RefHuman\"\n",
    "        self.remove_difficult = False\n",
    "\n",
    "        # -----------------------------\n",
    "        # Training Parameters\n",
    "        # -----------------------------\n",
    "        self.output_dir = \"./results/UniPHD_Results\"\n",
    "        self.note = \"\"\n",
    "        self.device = \"cuda\"\n",
    "        self.seed = 42\n",
    "\n",
    "        self.resume = \"\"                # checkpoint path\n",
    "        self.pretrain_model_path = None # external checkpoint\n",
    "        self.finetune_ignore = None     # list[str]\n",
    "\n",
    "        self.start_epoch = 0\n",
    "        self.eval = False\n",
    "        self.num_workers = 0\n",
    "        self.find_unused_params = False\n",
    "        self.save_log = False\n",
    "\n",
    "        # -----------------------------\n",
    "        # Distributed Training\n",
    "        # -----------------------------\n",
    "        self.world_size = 1\n",
    "        self.dist_url = \"env://\"\n",
    "        self.rank = 0\n",
    "        self.local_rank = 0\n",
    "        self.amp = False                # Mixed precision\n",
    "\n",
    "        # -----------------------------\n",
    "        # Additional Keys Updated Later\n",
    "        # -----------------------------\n",
    "        self.use_ema = False\n",
    "        self.debug = False\n",
    "\n",
    "        # -----------------------------\n",
    "        # MODEL NAME (REQUIRED FOR build_model_main)\n",
    "        # -----------------------------\n",
    "        # MUST be set to something like \"UniPHD\", \"UniRef\", \"UniSeg\", etc.\n",
    "        self.modelname = \"uniphd\"             # <---- you MUST fill this\n",
    "        self.num_classes = 2\n",
    "\n",
    "        self.lr = 0.0001\n",
    "        self.lr_adjacent_matrix = 1e-04\n",
    "        self.param_dict_type = 'default'\n",
    "        self.lr_backbone = 1e-05\n",
    "        self.lr_backbone_names = ['backbone.0']\n",
    "        self.lr_linear_proj_names = ['reference_points', 'sampling_offsets']\n",
    "        self.lr_linear_proj_mult = 0.1\n",
    "        self.lr_text_encoder = 0.0001\n",
    "        self.lr_text_encoder_names = ['text_encoder']\n",
    "        self.batch_size = 4\n",
    "        self.weight_decay = 0.0001\n",
    "        self.epochs = 20\n",
    "        self.lr_drop = 18\n",
    "        self.save_checkpoint_interval = 5\n",
    "        self.clip_max_norm = 0.1\n",
    "\n",
    "        self.modelname = 'uniphd'\n",
    "        self.frozen_weights = None\n",
    "        self.use_checkpoint = False\n",
    "        self.dilation = False\n",
    "        self.position_embedding = 'sine'\n",
    "        self.pe_temperatureH = 20\n",
    "        self.pe_temperatureW = 20\n",
    "        self.return_interm_indices = [0, 1, 2, 3]\n",
    "        self.backbone_freeze_keywords = None\n",
    "\n",
    "        # for transformer\n",
    "        self.hidden_dim = 256\n",
    "        self.dropout = 0.0\n",
    "        self.dim_feedforward = 2048\n",
    "        self.enc_layers = 6\n",
    "        self.dec_layers = 6\n",
    "        self.pre_norm = False\n",
    "        self.return_intermediate_dec = True\n",
    "        self.enc_n_points = 4\n",
    "        self.dec_n_points = 4\n",
    "        self.learnable_tgt_init = False\n",
    "        self.transformer_activation = 'relu'\n",
    "\n",
    "        # for main model\n",
    "        self.num_classes=2\n",
    "        self.nheads = 8\n",
    "        self.num_queries = 20\n",
    "        self.num_feature_levels = 4\n",
    "        self.dec_pred_class_embed_share = False\n",
    "        self.dec_pred_pose_embed_share = False\n",
    "        self.two_stage_type = 'standard'\n",
    "        self.two_stage_bbox_embed_share = False\n",
    "        self.two_stage_class_embed_share = False\n",
    "        self.cls_no_bias = False\n",
    "        self.num_body_points = 17\n",
    "\n",
    "        # for loss\n",
    "        self.focal_alpha = 0.25\n",
    "        self.cls_loss_coef = 2.0\n",
    "        self.bbox_loss_coef = 5.0\n",
    "        self.keypoints_loss_coef = 10.0\n",
    "        self.keypoints_visi_loss_coef = 4.0\n",
    "        self.oks_loss_coef=4.0\n",
    "        self.giou_loss_coef = 2.0\n",
    "        self.enc_loss_coef = 1.0\n",
    "        self.interm_loss_coef = 1.0\n",
    "        self.mask_loss_coef = 2.0\n",
    "        self.dice_loss_coef = 5.0\n",
    "        self.no_interm_loss = False\n",
    "        self.aux_loss = True\n",
    "\n",
    "        # for matcher\n",
    "        self.matcher_type = 'HungarianMatcher'\n",
    "        self.set_cost_class = 2.0\n",
    "        self.set_cost_bbox = 5.0\n",
    "        self.set_cost_giou = 2.0\n",
    "        self.set_cost_keypoints = 10.0\n",
    "        self.set_cost_keypoints_visi = 4.0\n",
    "        self.set_cost_oks=4.0\n",
    "        self.set_cost_kpvis = 0.0\n",
    "        self.set_cost_mask = 2.0\n",
    "        self.set_cost_dice = 5.0\n",
    "\n",
    "        # for postprocess\n",
    "        self.num_select = 20\n",
    "\n",
    "        # for ema\n",
    "        self.use_ema = False\n",
    "        self.ema_decay = 0.9997\n",
    "        self.ema_epoch = 0\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"For clean printing.\"\"\"\n",
    "        return \"\\n\".join([f\"{k}: {v}\" for k, v in self.__dict__.items()])\n",
    "\n",
    "\n",
    "args = UniPHDArgs()\n",
    "args.config_file = \"configs/uniphd.py\"\n",
    "args.modelname = \"uniphd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ae61b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_main():\n",
    "    from models.registry import MODULE_BUILD_FUNCS\n",
    "    assert 'uniphd' in MODULE_BUILD_FUNCS._module_dict\n",
    "    build_func = MODULE_BUILD_FUNCS.get('uniphd')\n",
    "    model, criterion, postprocessors = build_func(args)\n",
    "    return model, criterion, postprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b12c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, criterion, postprocessors = build_model_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5f2081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from util.misc import nested_tensor_from_tensor_list\n",
    "\n",
    "# Generate random input tensor (batch_size=2, 3 channels, 256x192 image)\n",
    "dummy_images = torch.randn(2, 3, 256, 192)\n",
    "\n",
    "# Generate dummy targets with captions (required by the model)\n",
    "dummy_targets = [\n",
    "    {'caption': 'A person standing'},\n",
    "    {'caption': 'A person sitting'}\n",
    "]\n",
    "\n",
    "# Move to device\n",
    "device = next(model.parameters()).device\n",
    "dummy_images = dummy_images.to(device)\n",
    "\n",
    "# Create NestedTensor from images\n",
    "samples = nested_tensor_from_tensor_list(dummy_images)\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = model(samples, dummy_targets)\n",
    "\n",
    "print(\"✅ Forward pass successful!\")\n",
    "print(f\"Output keys: {outputs.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969e171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Encoder: MiniLM\n",
    "from torchinfo import summary\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c315e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Encoder: RobertA\n",
    "from torchinfo import summary\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ae4fca",
   "metadata": {},
   "source": [
    "## Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8d59e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "img_dir= r'C:\\Users\\nikhi\\Desktop\\HuMAR\\datasets\\RefHuman_Small\\images'\n",
    "train_path = r'C:\\Users\\nikhi\\Desktop\\HuMAR\\datasets\\RefHuman_Small\\RefHuman_train2.json'\n",
    "with open(train_path, 'r', encoding='utf-8') as f:\n",
    "    train = json.load(f)\n",
    "val_path = r'C:\\Users\\nikhi\\Desktop\\HuMAR\\datasets\\RefHuman_Small\\RefHuman_val2.json'\n",
    "with open(val_path, 'r', encoding='utf-8') as f:\n",
    "    val = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19711dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_img_paths = os.listdir(img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995ca31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_paths = []\n",
    "for i in train['images']:\n",
    "    train_img_paths.append(i['file_name'])  \n",
    "val_img_paths = []\n",
    "for i in val['images']:\n",
    "    val_img_paths.append(i['file_name'])    \n",
    "train_img_paths = set(train_img_paths)\n",
    "val_img_paths = set(val_img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc63ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_small_img_paths = []\n",
    "val_small_img_paths = []\n",
    "\n",
    "for i in small_img_paths:\n",
    "    if i in train_img_paths:\n",
    "        train_small_img_paths.append(i)\n",
    "    elif i in val_img_paths:\n",
    "        val_small_img_paths.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18da33ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_imgs = []\n",
    "final_val_imgs = []\n",
    "for i in train_small_img_paths:\n",
    "    for j in train['images']:\n",
    "        if i == j['file_name']:\n",
    "            final_train_imgs.append(j)\n",
    "            break\n",
    "for i in val_small_img_paths:\n",
    "    for j in val['images']:\n",
    "        if i == j['file_name']:\n",
    "            final_val_imgs.append(j)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53f62c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['images'] = final_train_imgs\n",
    "val['images'] = final_val_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0460417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/RefHuman_Small/RefHuman_train.json', \"w\", encoding=\"utf-8\") as _f:\n",
    "    json.dump(train, _f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open('datasets/RefHuman_Small/RefHuman_val.json', \"w\", encoding=\"utf-8\") as _f:\n",
    "    json.dump(val, _f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b761c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10bc8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with different backbones\n",
    "# Available options:\n",
    "# MobileViT: 'mobilevit_xxs', 'mobilevit_xs', 'mobilevit_s'\n",
    "# SegFormer: 'segformer_mit_b0', 'segformer_mit_b1'\n",
    "# EfficientFormer: 'efficientformerv2_s0', 'efficientformerv2_s1', 'efficientformer_l1'\n",
    "# PoolFormer: 'poolformer_s12', 'poolformer_s24', 'poolformer_s36'\n",
    "# Swin: 'swin_T_224_1k'\n",
    "\n",
    "print(\"Current backbone:\", args.backbone)\n",
    "print(\"\\nTo test a different backbone, edit the UniPHDArgs class and set:\")\n",
    "print(\"self.backbone = 'your_chosen_backbone'\")\n",
    "print(\"\\nThen restart kernel and rebuild the model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7e5308",
   "metadata": {},
   "source": [
    "## Testing Fixed Backbones\n",
    "\n",
    "After restarting the kernel, you can test different backbones by changing `args.backbone` in the first cell."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
