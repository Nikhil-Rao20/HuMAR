"""
Complexity Comparison between Simple and Enhanced Multitask ReLA Models
"""
import torch
import torch.nn as nn
from test_multitask_model import SimplifiedMultitaskGRES as SimpleMultitaskGRES
from test_enhanced_multitask_model import EnhancedMultitaskGRES

def count_parameters(model):
    """Count total parameters in model"""
    return sum(p.numel() for p in model.parameters() if p.requires_grad)

def analyze_outputs(outputs, model_name):
    """Analyze model outputs"""
    print(f"\n{model_name} Outputs:")
    print("=" * 50)
    
    total_outputs = 0
    tensor_outputs = 0
    
    for key, value in outputs.items():
        total_outputs += 1
        if torch.is_tensor(value):
            tensor_outputs += 1
            print(f"  ‚úì {key}: {value.shape}")
        else:
            print(f"  ‚úì {key}: {type(value)} (complex structure)")
    
    print(f"\nSummary: {total_outputs} total outputs, {tensor_outputs} tensor outputs")
    return total_outputs, tensor_outputs

def main():
    print("üî¨ MULTITASK RELA MODEL COMPLEXITY COMPARISON")
    print("=" * 80)
    
    # Create models
    print("\n1. Creating Simple MultitaskGRES...")
    simple_model = SimpleMultitaskGRES()
    simple_params = count_parameters(simple_model)
    
    print("2. Creating Enhanced MultitaskGRES...")
    enhanced_model = EnhancedMultitaskGRES()
    enhanced_params = count_parameters(enhanced_model)
    
    # Prepare inputs
    images = torch.randn(2, 3, 512, 512)
    language_tokens = torch.randint(0, 1000, (1, 20))
    language_mask = torch.ones(1, 20).bool()
    
    # Test simple model
    print("\n3. Testing Simple Model...")
    simple_model.eval()
    with torch.no_grad():
        simple_outputs = simple_model(images, language_tokens, language_mask)
    
    simple_total, simple_tensors = analyze_outputs(simple_outputs, "Simple Model")
    
    # Test enhanced model
    print("\n4. Testing Enhanced Model...")
    enhanced_model.eval()
    with torch.no_grad():
        enhanced_outputs = enhanced_model(images, language_tokens, language_mask)
    
    enhanced_total, enhanced_tensors = analyze_outputs(enhanced_outputs, "Enhanced Model")
    
    # Comparison analysis
    print("\n" + "=" * 80)
    print("üìä COMPLEXITY COMPARISON ANALYSIS")
    print("=" * 80)
    
    print(f"\nüèóÔ∏è  Model Parameters:")
    print(f"  Simple Model:   {simple_params:,} parameters")
    print(f"  Enhanced Model: {enhanced_params:,} parameters")
    print(f"  Parameter Increase: {enhanced_params - simple_params:,} (+{((enhanced_params/simple_params - 1) * 100):.1f}%)")
    
    print(f"\nüìà Output Complexity:")
    print(f"  Simple Model:   {simple_total} outputs ({simple_tensors} tensors)")
    print(f"  Enhanced Model: {enhanced_total} outputs ({enhanced_tensors} tensors)")
    print(f"  Output Increase: +{enhanced_total - simple_total} outputs")
    
    # Analyze detection improvements
    print(f"\nüéØ Detection Head Improvements:")
    simple_det = [k for k in simple_outputs.keys() if k.startswith('det_')]
    enhanced_det = [k for k in enhanced_outputs.keys() if k.startswith('det_')]
    print(f"  Simple:   {len(simple_det)} detection outputs")
    print(f"  Enhanced: {len(enhanced_det)} detection outputs")
    print(f"  New Features: {set(enhanced_det) - set(simple_det)}")
    
    # Analyze pose improvements
    print(f"\nü§∏ Pose Head Improvements:")
    simple_pose = [k for k in simple_outputs.keys() if k.startswith('kpt_')]
    enhanced_pose = [k for k in enhanced_outputs.keys() if k.startswith('kpt_')]
    print(f"  Simple:   {len(simple_pose)} pose outputs")
    print(f"  Enhanced: {len(enhanced_pose)} pose outputs")
    print(f"  New Features: {set(enhanced_pose) - set(simple_pose)}")
    
    # Architecture complexity analysis
    print(f"\nüèõÔ∏è  Architecture Complexity:")
    print("  Simple Model:")
    print("    - Basic linear layers for detection/pose")
    print("    - Direct coordinate/bbox regression")
    print("    - Minimal feature extraction")
    print("\n  Enhanced Model:")
    print("    - Multi-layer transformer decoders")
    print("    - Self-attention and cross-attention mechanisms")
    print("    - Hierarchical prediction at multiple scales")
    print("    - Quality and confidence estimation")
    print("    - Anatomical structure awareness")
    print("    - Feature refinement through attention")
    print("    - Language-conditioned processing")
    
    # Key improvements summary
    print(f"\nüöÄ Key Enhancements Achieved:")
    print("  ‚úÖ Detection Head:")
    print("      - DetectionTransformerDecoder with 3 layers")
    print("      - Multi-head attention (8 heads)")
    print("      - Hierarchical classification & bbox regression")
    print("      - Detection confidence estimation")
    print("      - Spatial reasoning capabilities")
    
    print("  ‚úÖ Pose Head:")
    print("      - KeypointTransformerDecoder with 4 layers")
    print("      - Anatomical group attention")
    print("      - Multi-scale coordinate prediction")
    print("      - Pose quality assessment")
    print("      - Skeleton consistency validation")
    print("      - Human anatomy structure awareness")
    
    print("\nüéâ COMPLEXITY ENHANCEMENT SUCCESSFUL!")
    print("    Detection and Pose heads now match Segmentation head sophistication!")

if __name__ == "__main__":
    main()